import asyncio
import json
from typing import Final

from loguru import logger

import asr.app
import audio_player.service
import blip_img_cap.api
import controller.app
import minecraft.app
import obs.api
from bilibili import service as bili_serv
from gptsovits import api as gptsovits_serv
from minecraft.app import GameEvent
from scrnshot import api as scrn_serv
from tone_ana import api as tone_serv
from utils.datacls import Danmaku
from utils.util import is_blank
import asr.service

LANG = 'zh'
MAX_HISTORY = 40
DEV_NAME: Final[str] = 'èµ¤å·é¹¤é¸£'


def read_danmaku() -> Danmaku | None:
    """
    ä»è¿æ¥æˆåŠŸçš„ç›´æ’­é—´ä¸­æŒ‰ç…§ä¸€å®šçš„è§„åˆ™æŠ½å–å¼¹å¹•ã€‚
    å½“æ²¡æœ‰å¼¹å¹•å¯ä»¥è¢«æŠ½å–æ—¶ï¼Œè¿”å› None.
    :return: å¼¹å¹•å¯¹è±¡ | None
    """
    danmaku = bili_serv.select_latest_longest(k=3)
    if danmaku:
        logger.info(f'âœ… [{danmaku.username}]({danmaku.uid}) {danmaku.msg}')
    return danmaku


def read_screen() -> str | None:
    """
    ä»æŒ‡å®šçª—å£ä¸­è¯»å–æˆªå›¾å¹¶è¿”å›ä¸€æ®µè‹±æ–‡æè¿°ã€‚
    å½“æ²¡æœ‰æˆåŠŸæˆªå›¾æ˜¯ï¼Œè¿”å› None.
    :return:
    """
    img_save_path = scrn_serv.screen_cap()
    if img_save_path:
        caption = blip_img_cap.api.inference(img_save_path, prompt='There')
        return caption
    return None


def read_from_microphone() -> str | None:
    transcript = asr.service.select_latest_unread()
    if transcript:
        logger.info(f'ğŸ™ï¸ ç”¨æˆ·è¯­éŸ³è¾“å…¥ï¼š{transcript}')
    return transcript


def convert_2_query(transcript: str, danmaku: Danmaku, screen_desc: str, game_event: GameEvent) -> str | None:
    query = {}

    if transcript:
        query['å¼€å‘è€…è¯´'] = transcript
    if danmaku:
        query['å¼¹å¹•'] = {
            "ç”¨æˆ·å": danmaku.username,
            "å†…å®¹": danmaku.msg
        }

    if screen_desc:
        query['æ¸¸æˆç”»é¢'] = f'{screen_desc}'

    if game_event:
        query['æ¸¸æˆçŠ¶æ€'] = {
            "ç”Ÿå‘½å€¼": game_event.health,
            "é¥¥é¥¿å€¼": game_event.food,
            "ç¯å¢ƒ": game_event.environment
        }
    if query:
        query = str(json.dumps(obj=query, indent=4, ensure_ascii=False))
        query = f'```\n{query}\n```'
        return query
    return None


def tts_with_tone(sentence: str):
    """
    è‡ªåŠ¨åˆ†æå¥å­è¯­æ°”ï¼Œå¹¶åˆæˆè¯­éŸ³
    :param sentence: å°†è¦è¢«åˆæˆçš„æ–‡æœ¬
    :return: è¯­æ°”ï¼Œåˆæˆè¯­éŸ³çš„è·¯å¾„
    """
    # åˆ©ç”¨ LLM åˆ†æå¥å­è¯­æ°”
    tone = tone_serv.analyze_tone(sentence)

    # æ ¹æ®è¯­æ°”åˆ‡æ¢ TTS çš„æç¤ºåˆæˆå¯¹åº”çš„è¯­éŸ³
    wav_file_path = gptsovits_serv.predict_with_prompt(text_language=LANG, text=sentence,
                                                       refer_wav_path=tone.refer_wav_path,
                                                       prompt_text=tone.prompt_text,
                                                       prompt_language=tone.prompt_language)
    obs.api.write_tone_output(tone)

    return tone, wav_file_path


def read_game_event():
    return minecraft.app.select01()


async def life_circle():
    global LANG

    # å½“è®°å¿†è¿‡å¤šæˆ–æ²¡æœ‰è®°å¿†(æ‡’åŠ è½½)æ—¶, å°è¯•é‡è½½è®°å¿†
    controller.app.try_compress_history()

    # å°è¯•è¯»å–è¯­éŸ³ | æŠ½å–å¼¹å¹• | æˆªå›¾è¯†åˆ« | è·å–æ¸¸æˆäº‹ä»¶
    transcript = read_from_microphone()
    danmaku = read_danmaku()
    screen_desc = read_screen()
    game_event = read_game_event()

    # å°†ä¸Šè¿°è·å–çš„ä¿¡æ¯è½¬åŒ–ä¸ºå¯¹è¯çš„è¯·æ±‚
    query = convert_2_query(transcript, danmaku, screen_desc, game_event)

    if query is None or query == '':
        logger.warning('ç”Ÿå‘½å‘¨æœŸæå‰ç»“æŸ')
        return

    logger.info(query)

    # æ³¨æ„è¿™é‡Œ, å¼€å‘è€…è¯´çš„è¯ä¼šè¦†ç›–å¼¹å¹•
    if danmaku:
        obs.api.write_danmaku_output(danmaku)

    if transcript:
        obs.api.write_voice_input(DEV_NAME, transcript)

    # å…¶ä¸­ resp
    # ç¬¬1è½®å¾ªç¯ resp = 'æˆ‘'
    # ç¬¬2è½®å¾ªç¯ resp = 'æˆ‘æ˜¯'
    # ç¬¬3è½®å¾ªç¯ resp = 'æˆ‘æ˜¯ä¸€ä¸ª'
    # ç¬¬4è½®å¾ªç¯ resp = 'æˆ‘æ˜¯ä¸€ä¸ªæœºå™¨'
    # ç¬¬5è½®å¾ªç¯ resp = 'æˆ‘æ˜¯ä¸€ä¸ªæœºå™¨äºº'
    # ç¬¬6è½®å¾ªç¯ resp = 'æˆ‘æ˜¯ä¸€ä¸ªæœºå™¨äººã€‚'
    # ... ä»¥æ­¤ç±»æ¨

    last_split_idx = 0

    async for response, history in llm.chatglm3.api.stream_predict(query=query, history=controller.app.get_history(),
                                                                   top_p=1., temperature=1.):
        if not response or response[-1] not in ['ã€‚', 'ï¼', 'ï¼Ÿ', '!', '?']:
            continue

        sentence = response[last_split_idx:]
        last_split_idx = len(response)

        if is_blank(sentence):
            continue

        # æ›´æ–° LLM ä¼šè¯å†å²
        controller.app.set_history(history)

        # è‡ªåŠ¨è¯­æ°”è¯­éŸ³åˆæˆ
        tone, wav_file_path = tts_with_tone(sentence)

        logger.info(f'ğŸ—’ï¸ å†å²è®°å½•ï¼š{len(controller.app.get_history())} \nğŸ’– è¯­æ°”ï¼š{tone.id} \nğŸ’­ {sentence}')

        if not wav_file_path:
            logger.warning(f'â• è¿™æ¡è¯­éŸ³æœªèƒ½åˆæˆï¼š{sentence}')
            break

        # æ’­æ”¾è¯­éŸ³
        audio_player.service.add_audio(wav_file_path, sentence)


async def service_start():
    logger.info('ğŸ’œ ZerolanLiveRobotï¼Œå¯åŠ¨ï¼')
    while True:
        await life_circle()
        await asyncio.sleep(2)
