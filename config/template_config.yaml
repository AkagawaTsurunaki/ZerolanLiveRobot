# 注意：请在编辑后将此文件改名为 global_config.yaml以生效

# Bilibili 直播配置
bilibili_live_config:
  # 是否启动本服务
  enabled: True
  # 获取方式[详见](https://nemo2011.github.io/bilibili-api/#/get-credential)
  sessdata:
  bili_jct:
  buvid3:
  # 直播间 ID （应为数字）
  room_id:
# 截屏配置
screenshot_config:
  # 窗口标题（会自动查找符合该标题的第一个窗口）
  win_title:
  # 缩放因子（为了防止屏幕被截取窗口）
  k: 0.9
  # 截取的图片存放位置
  save_dir: .tmp/screenshots
# 模型 blip-image-captioning-large 的配置
blip_image_captioning_large_config:
  # 是否以调试模式运行
  debug: False
  # GPT-SoVITS 服务地址
  host: 127.0.0.1
  # GPT-SoVITS 服务端口
  port: 5926
  # 模型地址
  model_path: Salesforce/blip-image-captioning-large
  # 模型默认文本提示词（只能是英文）
  text_prompt: There
# GPT-SoVITS 服务配置
gpt_sovits_service_config:
  # 是否以调试模式运行
  debug: False
  # GPT-SoVITS 服务地址
  host: 127.0.0.1
  # GPT-SoVITS 服务端口
  port: 9880
  # 音频临时文件夹
  save_dir: .tmp/wav_output
# 语气分析服务配置
tone_analysis_service_config:
  # 语气模板地址
  tone_template_path: template/tone_analysis_template.yaml
  # 大语言模型判断一句话语气的提示词位置
  prompt_for_llm_path: template/tone_prompt_4_llm.json
# LLM 服务配置
llm_service_config:
  # LLM 服务名（即用什么模型）
  llm_name: chatglm3
  # LLM 服务地址
  host: 127.0.0.1
  # LLM 服务端口
  port: 9881
# OBS 服务配置
obs_config:
  # 弹幕输出字幕文件
  danmaku_output_path: .tmp/danmaku_output/output.txt
  # 语气输出字幕文件
  tone_output_path: .tmp/tone_output/output.txt
  # 大语言模型输出字幕文件
  llm_output_path: .tmp/llm_output/output.txt
# VAD 检测配置
vad_config:
  # 用户语音保存位置
  save_dir: .tmp/records
  # 块大小
  chunk: 4096
  # 采样率
  sample_rate: 16000
  # 激活阈值
  threshold: 600
  # 最大容许静音数
  max_mute_count: 10
# 自动语音识别配置
asr_config:
  # 语音识别模型路径
  speech_model_path: paraformer-zh
  # VAD 模型路径
  vad_model_path: fsmn-vad
  # 是否以调试模式运行
  debug: False
  # 自动语音识别服务地址
  host: 127.0.0.1
  # 自动语音识别服务端口
  port: 11005
# 本项目配置
zerolan_live_robot_config:
  # 是否以调试模式运行
  debug: False
  # ZerolanLiveRobot 服务地址
  host: 127.0.0.1
  # ZerolanLiveRobot 服务地址
  port: 11451
  # 提示词模板
  role_play_template_path: template/role_play_template.yaml

