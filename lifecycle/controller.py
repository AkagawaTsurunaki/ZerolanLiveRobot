import asyncio
import copy
import threading
from typing import List, Coroutine, Any

from loguru import logger
from zerolan.ui.api.toasts import Toast

from pipeline.llm import LLMPipeline
from zerolan_live_robot_core.abs_app import AppStatusEnum
from common.buffer.danmaku_buffer import DanmakuBufferObject
from common.buffer.game_buf import MinecraftGameEvent
from common.config.chara_config import CustomCharacterConfig, TTSPrompt
from common.decorator import log_run_time
from common.enum.lang import Language
from common.utils import file_util, audio_util
from lifecycle.env_data import CustomLiveStreamData
from services.device.speaker import Speaker
from services.filter.strategy import FirstMatchedFilter
from services.game.minecraft.app import KonekoMinecraftAIAgent
from pipeline.img_cap import ImaCapPipeline
from services.live_stream.bilibili.service import BilibiliService
from zerolan_live_robot_data.data.llm import LLMQuery, Conversation
from pipeline.pipeline import TTSPipeline, TTSQuery
from common.config.service_config import ServiceConfig as config
from common.utils.str_util import is_blank, split_by_punctuations, adjust_strings
from tasks.scnshoot_cap_task import ScreenshotCaptionTask
from tasks.sentiment_tts_prompt_task import SentimentTtsPromptTask


class Controller:
    def __init__(self):
        logger.info("åˆå§‹åŒ–æ§åˆ¶å™¨ä¸­...")
        # åŠ è½½è§’è‰²é…ç½®
        self._chara_config = CustomCharacterConfig()
        self._chara_config.load_config()
        self._history = [
                            Conversation(role="system", content=self._chara_config.system_prompt),
                        ] + copy.deepcopy(self._chara_config.example_cases)

        # Filter
        self._content_filter = FirstMatchedFilter()
        self._content_filter.set_words(self._chara_config.bad_words)

        # Services and Pipelines
        self._llm_pipeline = LLMPipeline()
        self._tts_pipeline = TTSPipeline()
        self._bilibli_service = BilibiliService()
        self._game_service = KonekoMinecraftAIAgent()
        self._imgcap_pipeline = ImaCapPipeline()

        # è¿™é‡Œå»æ£€éªŒæœåŠ¡æ˜¯å¦éƒ½å·²ç»å¯åŠ¨
        self.check_service_state()

        # Tasks
        self._scnshot_cap_task = ScreenshotCaptionTask(self._llm_pipeline, self._imgcap_pipeline)
        self.sentiment_tts_prompt_task = SentimentTtsPromptTask(self._llm_pipeline, self._chara_config.tts_prompts)
        self._game_task = None

        # Threads
        self.threads: List[threading.Thread] = []

        self._is_stream = False

    def check_service_state(self):
        """
        æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œã€‚å­˜åœ¨å¼‚å¸¸å°†ä¼šé€€å‡ºæ•´ä¸ªç¨‹åºã€‚
        """
        status = {"LLM": self._llm_pipeline.check_state(),
                  "TTS": self._tts_pipeline.check_state(),
                  "Image Captioning": self._imgcap_pipeline.check_state()}
        flag = False
        for service, state in status.items():
            if state.state != AppStatusEnum.RUNNING:
                logger.error(f"{service} æœåŠ¡å¼‚å¸¸")
                flag = True

        if flag:
            msg = "éƒ¨åˆ†å…³é”®æœåŠ¡å­˜åœ¨å¼‚å¸¸ï¼Œè¿›ç¨‹ç»“æŸã€‚"
            logger.error(msg)
            Toast(message=msg, level="error").show_toast()
            exit(0)

    async def awake(self):
        if config.live_stream_config.enable:
            self.threads.append(threading.Thread(target=self._bilibli_service.start))
        if config.game_config.enable:
            self._game_task = asyncio.create_task(self._game_service.start())

        for thread in self.threads:
            thread.start()

    @log_run_time(lambda time_used: f"æ”¶é›†ç¯å¢ƒä¿¡æ¯ç”¨æ—¶ {time_used} ç§’")
    async def collect_env_input(self) -> CustomLiveStreamData | None:
        # è·å–ç›´æ’­é—´å¼¹å¹•
        dbo: DanmakuBufferObject | None = None
        if config.live_stream_config.enable:
            dbo = self._bilibli_service.danmaku_buf.select_latest_longest(k=4)

        # è·å–æ¸¸æˆç”»é¢æè¿°ï¼ˆå¼‚æ­¥ï¼‰
        scnshot_cap_task = self._scnshot_cap_task.run(win_title='Minecraft', k=0.8)

        # è·å–æ¸¸æˆäº‹ä»¶
        game_event: MinecraftGameEvent | None = None
        if config.game_config.enable:
            game_event = self._game_service.game_evt_buf.select_last_one_and_clear()
        game_scn = None

        # å°†ç”»é¢è§£é‡Šä¸ºè‡ªç„¶è¯­è¨€
        try:
            game_scn = await scnshot_cap_task
        except Exception as e:
            logger.exception(e)
            Toast(message="ğŸ§ â‡†âŒï¸â‡†ğŸ‘ï¸ è§†è§‰ç³»ç»Ÿæ•…éšœ", level="error").show_toast()

        result = CustomLiveStreamData(dev_say="",
                                      danmaku=dbo.danmaku if dbo is not None else None,
                                      game_scene=game_scn if not is_blank(game_scn) else None,
                                      game_event=game_event if game_event is not None else None)
        if result.is_meaningful():
            logger.debug("ç¯å¢ƒæ•°æ®é‡‡é›†å®Œæ¯•")
            return result
        else:
            logger.warning("æ— ç¯å¢ƒä¿¡æ¯é‡‡é›†")
            return None

    async def update(self):
        env = await self.collect_env_input()
        if not env:
            return

        llm_query = LLMQuery(text=env.interpret(), history=self._history)

        if self._is_stream:
            # æµå¼æ¨ç†
            # å½“ä½ çš„ GPU è¿ç®—é€Ÿç‡æœ‰é™ï¼Œæˆ–è€…ç“¶é¢ˆåœ¨ LLM æ¨ç†æ—¶è¯·å¼€å¯æµå¼æ¨ç†
            raise NotImplementedError("è¿™ä¸€éƒ¨åˆ†å°šæœªå®ç°")
        else:
            # éæµå¼æ¨ç†
            # éæµå¼æ¨ç†å½“æ‚¨çš„ GPU è¿ç®—é€Ÿç‡å¤Ÿå¿«ï¼Œå¯ä»¥å¿½ç•¥ LLM æ¨ç†æ—¶çš„å»¶æ—¶æ—¶å¯ä»¥å°è¯•å¯ç”¨
            try:
                llm_prediction = self._llm_pipeline.predict(llm_query)
            except Exception as e:
                logger.exception(e)
                Toast(message="ğŸ§ â‡†âŒï¸â‡†ğŸ’­ è¯­è¨€ç³»ç»Ÿæ•…éšœ", level="error").show_toast()
                raise e
            self._history = llm_prediction.history
            logger.info(f"è§’è‰²è¯´ï¼š{llm_prediction.response}")

            ### TODO: Remember to test here
            if not self._content_filter.filter(llm_prediction.response):
                logger.warning("æœ¬æ¬¡å¯¹è¯å­˜åœ¨æ•æ„Ÿå†…å®¹ï¼Œå·²è¢«è¿‡æ»¤")
                return
            ###

            # å¸¦æƒ…æ„Ÿçš„è¯­éŸ³åˆæˆå’Œæ’­æ”¾
            tts_prompt = await self.sentiment_tts_prompt_task.run(llm_prediction.response)

            sentences = split_by_punctuations(llm_prediction.response)
            sentences = adjust_strings(sentences, 15)
            tts_tasks: List[Coroutine[Any, Any, str]] = []
            for sentence in sentences:
                tts_tasks.append(self.tts(sentence, tts_prompt))

            for idx, tts_task in enumerate(tts_tasks):
                tmp_wav_file = await tts_task
                _, _, duration = audio_util.check_wav_info(tmp_wav_file)
                Toast(message=sentences[idx], duration=duration, level="info").show_toast()
                Speaker.playsound(tmp_wav_file, block=True)

    async def tts(self, sentence: str, tts_prompt: TTSPrompt):
        tts_query = TTSQuery(text=sentence,
                             text_language=Language.ZH.name(),
                             refer_wav_path=tts_prompt.audio_path,
                             prompt_text=tts_prompt.transcript,
                             prompt_language=tts_prompt.lang.name())
        try:
            tts_prediction = self._tts_pipeline.predict(query=tts_query)
        except Exception as e:
            logger.exception(e)
            Toast(message="ğŸ§ â‡†âŒï¸â‡†ğŸ—£ï¸ è¯­éŸ³ç³»ç»Ÿæ•…éšœ", level="error").show_toast()
            raise e

        tmp_wav_file = file_util.create_temp_file(prefix="tts", suffix=".wav", tmpdir="audio")
        with open(tmp_wav_file, "wb") as f:
            f.write(tts_prediction.wave_data)

        return tmp_wav_file
