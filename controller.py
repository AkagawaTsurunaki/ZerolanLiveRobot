import asyncio
import json
import os

from loguru import logger

from chatglm3 import service as chatglm3_serv
from audio_player import service as audio_player_serv
from bilibili import service as bili_serv
from blip_img_cap.service import infer
from chatglm3.service import ModelRequest
from gptsovits import service as tts_serv
from obs.service import write_output
from scrnshot import service as scrn_serv
from tone_ana import service as tone_serv
from utils.util import is_blank

# æ§åˆ¶æ­»å¾ªç¯
FLAG = True
LANG = 'zh'

# ä¸€äº›é»˜è®¤è·¯å¾„
# OBS å­—å¹•æ–‡ä»¶
DEFAULT_EMOTION_OUTPUT_PATH = '.tmp/emotion_output/emotion.txt'  # é»˜è®¤å¿ƒæƒ…æ ‡ç­¾è¾“å‡ºæ–‡ä»¶å¤¹
DEFAULT_LLM_OUTPUT_PATH = '.tmp/llm_output/chatglm3.txt'  # é»˜è®¤å¤§è¯­è¨€æ¨¡å‹çš„è¾“å‡ºè·¯å¾„
DEFAULT_DANMAKU_OUTPUT_PATH = '.tmp/danmaku/bilibili.txt'  # é»˜è®¤å¼¹å¹•çš„è¾“å‡ºè·¯å¾„
# æ¨¡æ¿æ–‡ä»¶
DEFAULT_CUSTOM_PROMPT_FILE_PATH = 'template/custom_prompt2.json'  # ç”¨æˆ·è‡ªå®šä¹‰çš„æç¤ºè¯æ¨¡æ¿


def load_llm_sys_prompt():
    """
    åŠ è½½ç”¨æˆ·è‡ªå®šä¹‰çš„æç¤ºè¯æ¨¡æ¿ã€‚
    å¦‚æœåœ¨é»˜è®¤è·¯å¾„ {DEFAULT_CUSTOM_PROMPT_FILE_PATH} ä¸‹æ‰¾ä¸åˆ°å¯¹åº”çš„æ–‡ä»¶ï¼Œé‚£ä¹ˆå°±ä¼šåˆ›å»ºä¸€ä¸ªã€‚
    :return: ModelRequest
    """

    # å¦‚æœç”¨æˆ·æ²¡æœ‰è®¾ç½®è‡ªå·±çš„è‡ªå®šä¹‰æç¤ºè¯ï¼Œé‚£ä¹ˆè‡ªåŠ¨ä½¿ç”¨é»˜è®¤æç¤ºè¯
    if not os.path.exists(DEFAULT_CUSTOM_PROMPT_FILE_PATH):
        with open(file=DEFAULT_CUSTOM_PROMPT_FILE_PATH, mode='w+', encoding='utf-8') as file:
            model_req = ModelRequest(sys_prompt='', query='', temperature=1., top_p=1., history=[])
            json.dump(obj=model_req, fp=file, ensure_ascii=False, indent=4)
            logger.warning(
                f'å·²ç”Ÿæˆç”¨æˆ·è‡ªå®šä¹‰çš„æç¤ºè¯æ¨¡æ¿ï¼Œæ‚¨å¯ä»¥åˆ°ä»¥ä¸‹è·¯å¾„è¿›è¡Œå…·ä½“å†…å®¹ä¿®æ”¹ï¼š{DEFAULT_CUSTOM_PROMPT_FILE_PATH}')

    with open(file=DEFAULT_CUSTOM_PROMPT_FILE_PATH, mode='r', encoding='utf-8') as file:
        json_value = json.load(file)
        model_req = ModelRequest(**json_value)
    logger.info(f'LLM æç¤ºè¯æ¨¡æ¿åŠ è½½å®Œæ¯•')
    return model_req


default_model_req: ModelRequest = load_llm_sys_prompt()


async def circle():
    """
    å¯åŠ¨ ZerolanLiveRobot ç”Ÿå‘½å‘¨æœŸ
    æ¯ä¸€ä¸ªç”Ÿå‘½å‘¨æœŸä¸­ï¼Œä¼šå…ˆæ£€æŸ¥æ˜¯å¦æœ‰å¯è¯»çš„å¼¹å¹• Danmakuï¼Œå¹¶å°†å¼¹å¹•å†…å®¹æ‹¼æ¥è¿› LLM çš„ ModelRequest è¯·æ±‚ä¸­ï¼Œ
    å¾… LLM æœåŠ¡æŒ‰ç…§æµå¼è¿”å›ä¸€å¥æ•´å¥ Sentence åï¼Œå†åˆ©ç”¨ LLM æœåŠ¡åˆ†æå…¶å¿ƒæƒ… Emotionï¼Œ
    æŒ‰ç…§ Emotion æ›´æ”¹æç¤ºè¯ï¼Œ
    :return:
    """
    # æŸ¥çœ‹æ˜¯å¦æœ‰å¯ä»¥é€‰æ‹©çš„å¼¹å¹•
    danmaku = bili_serv.select_01(k=3)

    if danmaku:
        logger.info(f'âœ… [{danmaku.username}]({danmaku.uid}) {danmaku.msg}')

    img = scrn_serv.screen_cap()
    gamescn = infer(img, '') if img else None

    # å°è£…ä¸ºä¸€ä¸ªæ¨¡å‹è¯·æ±‚ä½“

    default_model_req.sys_prompt = ''
    if gamescn and danmaku:
        default_model_req.query = '{\n\t' + f'"{danmaku.username}": "{danmaku.msg}"' + '\n\t' + f'"gamescn": "{gamescn}"' + '\n' + '}'
    elif danmaku:
        default_model_req.query = '{\n\t' + f'"{danmaku.username}": "{danmaku.msg}"' + '\n' + '}'
    elif gamescn:
        default_model_req.query = '{\n\t' + f'"gamescn": "{gamescn}"' + '\n' + '}'
    else:
        return

    logger.info(f'ğŸ®ï¸ {gamescn}')
    # å…¶ä¸­ resp
    # ç¬¬1è½®å¾ªç¯ resp = 'æˆ‘'
    # ç¬¬2è½®å¾ªç¯ resp = 'æˆ‘æ˜¯'
    # ç¬¬3è½®å¾ªç¯ resp = 'æˆ‘æ˜¯ä¸€ä¸ª'
    # ç¬¬4è½®å¾ªç¯ resp = 'æˆ‘æ˜¯ä¸€ä¸ªæœºå™¨'
    # ç¬¬5è½®å¾ªç¯ resp = 'æˆ‘æ˜¯ä¸€ä¸ªæœºå™¨äºº'
    # ç¬¬6è½®å¾ªç¯ resp = 'æˆ‘æ˜¯ä¸€ä¸ªæœºå™¨äººã€‚'
    # ... ä»¥æ­¤ç±»æ¨

    now = ''

    for model_resp in chatglm3_serv.stream_predict(query=default_model_req.sys_prompt + default_model_req.query,
                                                   history=default_model_req.history, top_p=default_model_req.top_p,
                                                   temperature=default_model_req.temperature):
        resp = model_resp.response
        # æŒ‰ç…§æ ‡ç‚¹ç¬¦å·åˆ‡å‰²å¥å­
        if not resp:
            continue

        if resp[-1] not in ['ã€‚', 'ï¼', 'ï¼Ÿ', '!', '?']:
            continue

        # ä¿ç•™å•å¥
        sentence = resp[len(now): len(resp)]
        now = now + sentence

        if is_blank(sentence):
            continue

        if len(sentence) < 6:
            continue

        # æ›´æ–°å†å²
        default_model_req.history = model_resp.history
        logger.debug(f'å½“å‰ LLM å†å²è®°å½•ï¼š{len(default_model_req.history)}')

        # åˆ†æå¥å­çš„æƒ…æ„Ÿå€¾å‘
        emotion = tone_serv.analyze_tone(sentence)
        logger.info(f'å¿ƒæƒ…ï¼š{emotion.id}')

        # æ ¹æ®å¿ƒæƒ…åˆ‡æ¢ Prompt
        tts_serv.change_prompt(emotion.refer_wav_path, emotion.prompt_text, emotion.prompt_language)

        # TTS ä»»åŠ¡
        wav_file_path = tts_serv.predict(sentence, LANG)

        # å†™å…¥å¿ƒæƒ…
        write_output(danmaku, sentence, emotion)

        # å¦‚æœéŸ³é¢‘æ–‡ä»¶ä¸ä¸ºç©ºï¼ˆå¦‚æœæœåŠ¡å™¨å‡ºé”™ï¼Œåˆ™ä¸ºç©ºï¼‰ï¼Œåˆ™æ’­æ”¾éŸ³é¢‘
        if not wav_file_path:
            logger.warning(f'è¿™æ¡è¯­éŸ³æœªèƒ½åˆæˆï¼š[{LANG}] {sentence}')
            continue
        audio_player_serv.play(wav_file_path=wav_file_path, transcript=resp)

        # ç»§ç»­LLMçš„è¿ç®—
        await asyncio.sleep(0)  # è®©å‡ºæ§åˆ¶æƒï¼Œè®©äº‹ä»¶å¾ªç¯æ‰§è¡Œå…¶ä»–ä»»åŠ¡


async def start_life_cycle():
    """
    å¯åŠ¨ç”Ÿå‘½å‘¨æœŸ
    :return:
    """
    bili_live_start = asyncio.create_task(bili_serv.start())
    while FLAG:
        await circle()
        await asyncio.sleep(1)
    await bili_live_start


if __name__ == '__main__':
    # åœ¨è°ƒç”¨ circle() çš„åœ°æ–¹ï¼Œéœ€è¦ä½¿ç”¨ asyncio.run() æˆ–è€…åœ¨ asyncio äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œè¯¥å‡½æ•°
    asyncio.run(start_life_cycle())
